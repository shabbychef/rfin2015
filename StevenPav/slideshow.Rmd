---
title: Portfolio Cram√©r-Rao bounds
subtitle: (why bad things happen to good quants)
author: Steven E. Pav
job: Cerebellum Capital
framework: io2012
widgets: [mathjax]
---

```{r setup,cache=FALSE,echo=FALSE,message=FALSE,warning=FALSE}
options(width=80,digits=2)
library(SharpeR)
library(ggplot2)
library(reshape2)
library(knitr)
```

### Why does this happen? 

<img src="http://www.imgur.com/5oOkkSR.jpg" width="500">

---

### Why overfit happens

For 'bad' quants:
- Plain old overfit ('p-value hacking').
- Broken backtests: lookahead bias, survivorship bias, _etc._
- Bad understanding of trade costs. 
- Bad execution.

For 'good' quants:
- Bad luck.
- A fundamental bound.

---

### A fundamental bound?

Consider portfolio estimator as function:
- The input is historical data, the $T\times p$ matrix $X$, say.
- The output is the portfolio, a $p$ vector.

Consider the (population) Sharpe ratio of this portfolio,
its expected value divided by its volatility. 


We will bound the expected Sharpe, with expectation over draws
of $X$.

---

### The bound

$$
\mbox{Cramer Rao} + \mbox{geometry} + \mbox{math} => \mbox{bound on expected Sharpe}.
$$

Under a wide range of conditions the bound is:
$$
E_X\left[Sharpe\right] \le \sqrt{\frac{\mbox{effect size}}{\mbox{# knobs} + \mbox{effect size}}} \mbox{maximal Sharpe},
$$
with $\mbox{effect size} = \mbox{# years}\, (\mbox{maximal Sharpe})^2.$

---

### Control your free variables

```{r control, include=FALSE}
nyr <- 5
zeta <- 1.1
qbound <- function(df,n,zeta) {
	effst <- n * zeta^2
	ebnd <- sqrt(effst / (df + effst)) * zeta
}
nstok1 <- 10
myq1 <- qbound(nstok1 -1,nyr,zeta)
nstok2 <- 40
myq2 <- qbound(nstok2 -1,nyr,zeta)
nstok3 <- 160
myq3 <- qbound(nstok3 -1,nyr,zeta)
```
This is why portfolio optimization is not performed on 100's of unknowns:

If maximal Sharpe is $`r zeta`$, observing $`r nyr` \mbox{yr}$ of data:
- for $`r nstok1`$ stocks, the bound is $`r myq1`$.
- for $`r nstok2`$ stocks, the bound is $`r myq2`$.
- for $`r nstok3`$ stocks, the bound is $`r myq3`$.

However, maximal Sharpe should grow with universe size.
Can it grow fast enough?

--- 

### Diversification and universe size

For $\mbox{Sharpe} = p^{\gamma}$, plot bound vs. $p$ for
different $\gamma$. Fundamental change at $\gamma=1/4$.

```{r show_grow_bound,echo=FALSE,cache=TRUE}

ope <- 253
n.stok <- 6
n.yr <- 4
n.obs <- ceiling(ope * n.yr)
zeta.s <- 1.25 / sqrt(ope)   # optimal SNR, in daily units

bound.experiment <- function(pow,n.obs,zeta.s,
		n.stok=n.stok,ope=ope,plims=c(2,250)) {
	require(reshape2)
	all.ps <- unique(round(exp(seq(log(min(plims)),
																	log(max(plims)),
																	length.out=140))))
	zeta.0 <- zeta.s / (n.stok ^ pow)
	all.zeta <- zeta.0 * (all.ps ^ pow)
	all.bnd <- sqrt(ope * n.obs) * all.zeta^2 / sqrt(all.ps - 1 + n.obs * all.zeta^2)

	#population.max=sqrt(ope) * all.zeta,
	foo.df <- data.frame(p=all.ps,
		pow=rep(pow,length(all.bnd)),
		bound=all.bnd)
	measure.vars <- colnames(foo.df)
	id.vars <- c("p","pow")
	measure.vars <- measure.vars[! measure.vars %in% id.vars]
	require(reshape2)
	melt.df <- melt(foo.df,id.vars=id.vars,variable.name="Sharpe",
		measure.vars=measure.vars)
	return(melt.df)
}

#	plims = c(2,250)
#	melt.df <- NULL
#	for (ppp in pow) {
#		addon.df <- bound.experiment(ppp,n.obs,zeta.s,n.stok=n.stok,ope=ope,plims=plims)
#		if (is.null(melt.df))
#			melt.df <- addon.df
#		else
#			melt.df <- rbind(melt.df,addon.df)
#	}
#	#as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
#	melt.df$pow <- as.numeric(melt.df$pow)
#
#	require(ggplot2)
#	ph <- ggplot(data=melt.df,aes(x=p,y=value,group=pow,colour=pow))
#	ph <- ph + geom_line()
#	ph <- ph + labs(x="# assets",
#									y="Signal-Noise ratio (annualized)")
#	ph <- ph + scale_x_log10(limits = c(1,max(plims)))
#	ph <- ph + scale_y_log10(limits = c(0.5,4),
#		breaks=2^seq(from=-1,to=2,by=0.5))
#	print(ph)

bound.plot <- function(pow,n.obs,zeta.s,plims=c(2,250),...) {
	melt.df <- NULL
	for (ppp in pow) {
		addon.df <- bound.experiment(ppp,n.obs,zeta.s,plims=plims,...)
		if (is.null(melt.df))
			melt.df <- addon.df
		else
			melt.df <- rbind(melt.df,addon.df)
	}
	melt.df$gamma <- factor(melt.df$pow)

	require(ggplot2)
	ph <- ggplot(data=melt.df,aes(x=p,y=value,group=gamma,colour=gamma))
	ph <- ph + geom_line()
	ph <- ph + labs(x="# assets",
									y="Signal-Noise ratio (annualized)")
	ph <- ph + guides(colour=guide_legend(title=expression(gamma)))
	ph <- ph + scale_x_log10(limits = c(1,max(plims)))
	ph <- ph + scale_y_log10(limits = c(0.5,4),
		breaks=2^seq(from=-1,to=2,by=0.5))
	return(ph)
}

pgammas <- seq(from=0.15,to=0.35,by=0.05)

sgammas <- sort(pgammas)
sgammas.txt <- paste0(paste0(sgammas[1:(length(sgammas)-1)],collapse=', '),", and ",sgammas[length(sgammas)],sep='')
sgammas.summary <- paste0("between ",sgammas[1]," and ",sgammas[length(sgammas)])

print(bound.plot(pgammas,n.obs=n.obs,zeta.s=zeta.s,
	n.stok=n.stok,ope=ope))

```

---
### Diversification in the S&P 100

```{r load_sp100,eval=TRUE,echo=FALSE,warning=FALSE,results='hide'}

require(Quandl)
# sooper secret key
Quandl.auth(Sys.getenv('R_QUANDL_AUTH',unset="GETYOUROWNKEYAND_PUT"))
require(xts)

# this list is aso of 2014-03-21
asof <- 'March 21, 2014'
splist <- c("AAPL", "ABBV", "ABT", "ACN", "AIG", "ALL", "AMGN", "AMZN", "APA", 
						"APC", "AXP", "BA", "BAC", "BAX", "BIIB", "BK", "BMY", "BRK_B",
						"C", "CAT", "CL", "CMCSA", "COF", "COP", "COST", "CSCO", "CVS",
						"CVX", "DD", "DIS", "DOW", "DVN", "EBAY", "EMC", "EMR", "EXC", "F",
						"FB", "FCX", "FDX", "FOXA", "GD", "GE", "GILD", "GM", "GOOG", "GS",
						"HAL", "HD", "HON", "HPQ", "IBM", "INTC", "JNJ", "JPM", "KO",
						"LLY", "LMT", "LOW", "MA", "MCD", "MDLZ", "MDT", "MET", "MMM",
						"MO", "MON", "MRK", "MS", "MSFT", "NKE", "NOV", "NSC", "ORCL",
						"OXY", "PEP", "PFE", "PG", "PM", "QCOM", "RTN", "SBUX", "SLB",
						"SO", "SPG", "T", "TGT", "TWX", "TXN", "UNH", "UNP", "UPS", "USB",
						"UTX", "V", "VZ", "WAG", "WFC", "WMT", "XOM")

get.ret <- function(tickr,ntries=5) {
	the.pry <- NULL
	attempt <- 1L
	while (is.null(the.pry) && attempt <= ntries) {
		attempt <- attempt + 1
		try(
			the.pry <- Quandl(paste0('YAHOO/',tickr),
												collapste="weekly",type="xts",
												start_date="2009-03-15",end_date="2014-03-31")
		)
	}

	if (is.null(the.pry)) {
		warning(paste0(tickr,' failed to load?'))
	}
	tryCatch({
		the.ac <- to.weekly(the.pry[,"Adjusted Close",drop=FALSE],indexAt='endof')
		the.ac <- the.ac[,dim(the.ac)[2]]
		# move to sundays?
		index(the.ac) <- time(the.ac) + (4 - .indexwday(the.ac))
		log.ret <- diff(log(the.ac),k=1)
		colnames(log.ret) <- c(tickr)
	}, error= function(e) e,
	finally = print(paste0('done with ',tickr)))
	return(log.ret)
}

allrets <- lapply(splist,get.ret)
all.lr <- do.call(cbind,allrets)
OEX.lr <- get.ret('INDEX_OEX')

# trim first row
sub.lr <- all.lr[2:dim(all.lr)[1],]
ok.col <- colSums(is.na(sub.lr)) == 0
sub.lr <- sub.lr[,ok.col]
```

```{r inference_sp100,eval=TRUE,echo=FALSE,warning=FALSE,results='hide'}
require(SharpeR)
# compute MLE and KRS estimators on maximal SR
# in alphabetical order
MLEs <- unlist(lapply(1:dim(sub.lr)[2],function(n) {
								inference(as.sropt(sub.lr[,1:n]),"MLE") }))
KRSs <- unlist(lapply(1:dim(sub.lr)[2],function(n) {
								inference(as.sropt(sub.lr[,1:n]),"KRS") }))

# try for random reorderings:
set.seed(12312L)
buncho.KRSs <- replicate(1000,unlist(lapply(sample.int(dim(sub.lr)[2]),function(n) {
								inference(as.sropt(sub.lr[,1:n]),"KRS") })))

```

```{r plot_KRS_sp100,eval=TRUE,echo=FALSE,warning=FALSE,results='asis'}
foo.df <- data.frame(df=rep(1:(dim(buncho.KRSs)[1]),dim(buncho.KRSs)[2]),
	KRS=as.vector(t(buncho.KRSs)))
foo.df <- foo.df[foo.df$df < 11,]

require(ggplot2)
ph <- ggplot(data=foo.df,aes(x=factor(df),y=KRS))
ph <- ph + geom_boxplot()
ph <- ph + labs(x="# assets",
								y=expression(zeta["*"]))
print(ph)
```

---
### Learn More

- Read the [paper](http://arxiv.org/abs/1409.5936)
- Try the shiny app:
```{r demo,eval=FALSE}
library(shiny)
shiny::runGitHub('rfin2015','shabbychef',subdir='StevenPav/app')
```
- Ask me questions.
- Thank you.

